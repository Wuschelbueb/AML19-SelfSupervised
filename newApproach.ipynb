{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'fashion_mnist'\n",
    "batch_size=64\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = FashionMNIST(root=root_dir, download=True, train=True, transform=transform)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = FashionMNIST(root=root_dir, download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMinstAugmentedDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, target, transform):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        \n",
    "        datapoint = self.transform(self.data[index], angle)\n",
    "        \n",
    "        # need to use ints for classes [0, 90, 180, 270]\n",
    "        if angle == 0:\n",
    "            rotation_class = 0 \n",
    "        if angle == 90:\n",
    "            rotation_class = 1\n",
    "        if angle == 180:\n",
    "            rotation_class = 2\n",
    "        if angle == 270:\n",
    "            rotation_class = 3\n",
    "        \n",
    "        target = rotation_class\n",
    "\n",
    "        return datapoint, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate given images by given angle\n",
    "\n",
    "def my_segmentation_transforms(image, angle):\n",
    "    image = TF.to_pil_image(image)\n",
    "    image = TF.resize(image, 32, interpolation=2)\n",
    "    image = TF.rotate(image, angle)\n",
    "    image = TF.to_tensor(image)\n",
    "    image = TF.normalize(image, (0.5, ), (0.5, ))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "n_train = int(len(trainset) * 0.8)\n",
    "\n",
    "train_augmented = FashionMinstAugmentedDataset(\n",
    "#     data=trainset.data[:n_train], \n",
    "    data=trainset.data[:100], \n",
    "#     target=trainset.targets[:n_train], \n",
    "    target=trainset.targets[:100], \n",
    "    transform=my_segmentation_transforms)\n",
    "trainloader_augmented = DataLoader(train_augmented, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "\n",
    "val_augmented = FashionMinstAugmentedDataset(\n",
    "#     data=trainset.data[n_train:], \n",
    "    data=trainset.data[100:200],\n",
    "#     target=trainset.targets[n_train:], \n",
    "    target=trainset.targets[100:200], \n",
    "    transform=my_segmentation_transforms)\n",
    "valloader_augmented = DataLoader(val_augmented, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "\n",
    "test_augmented = FashionMinstAugmentedDataset(\n",
    "    data=testset.data, \n",
    "    target=testset.targets, \n",
    "    transform=my_segmentation_transforms)\n",
    "testloader_augmented = DataLoader(test_augmented, batch_size=batch_size, shuffle=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train(model, loss_fn, optimizer, scheduler, num_epochs, trainloader, valloader):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    dataloader = None\n",
    "    dataset_size = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "                dataloader = trainloader\n",
    "                dataset_size = len(trainloader.dataset)\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valloader\n",
    "                dataset_size = len(valloader.dataset)\n",
    "\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            \n",
    "            for data in dataloader:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                #print(\"outputs:\", outputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                #print(\"labels:\", labels)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects / dataset_size\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def flatten(x): \n",
    "    return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1       \n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residue = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residue = self.downsample(x)\n",
    "\n",
    "        out += residue\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        residue = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(x)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residue = self.downsample(x)\n",
    "\n",
    "        out += residue\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "            \n",
    "            \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, depth, name, num_classes=10, block=BasicBlock):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        assert (depth - 2) % 6 == 0, 'Depth should be 6n + 2'\n",
    "        n = (depth - 2) // 6\n",
    "\n",
    "        self.name = name\n",
    "        block = BasicBlock\n",
    "        self.inplanes = 16\n",
    "        fmaps = [16, 32, 64] # CIFAR10\n",
    "\n",
    "        self.conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, fmaps[0], n, stride=1)\n",
    "        self.layer2 = self._make_layer(block, fmaps[1], n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, fmaps[2], n, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
    "        self.flatten = flatten\n",
    "        self.fc = nn.Linear(fmaps[2] * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        ''' Between layers convolve input to match dimensions -> stride = 2 '''\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                    nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                              kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, print_sizes=False):\n",
    "        \n",
    "        if print_sizes:\n",
    "            print('Sizes of the tensors inside each node: \\n')\n",
    "            print(\"\\t In Model: input size\", x.size())\n",
    "        \n",
    "        x = self.relu(self.bn(self.conv(x)))    # 32x32\n",
    "        \n",
    "        x = self.layer1(x)                      # 32x32\n",
    "        x = self.layer2(x)                      # 16x16\n",
    "        x = self.layer3(x)                      # 8x8\n",
    "\n",
    "        x = self.avgpool(x)                     # 1x1\n",
    "        x = self.flatten(x)                     # Flatten\n",
    "        x  = self.fc(x)                         # Dense\n",
    "        \n",
    "        if print_sizes:\n",
    "            print(\"\\t In Model: output size\", x.size())\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet20(**kwargs):    \n",
    "    return ResNet(name = 'ResNet20', depth = 20, num_classes=4,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet20 = ResNet20()\n",
    "resnet20.conv = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "train Loss: 0.0554 Acc: 0.2700\n",
      "val Loss: 0.0553 Acc: 0.2400\n",
      "Epoch 2/5\n",
      "train Loss: 0.0491 Acc: 0.4100\n",
      "val Loss: 0.0563 Acc: 0.2700\n",
      "Epoch 3/5\n",
      "train Loss: 0.0439 Acc: 0.4300\n",
      "val Loss: 0.0633 Acc: 0.1900\n",
      "Epoch 4/5\n",
      "train Loss: 0.0466 Acc: 0.4800\n",
      "val Loss: 0.0755 Acc: 0.2800\n",
      "Epoch 5/5\n",
      "train Loss: 0.0453 Acc: 0.4700\n",
      "val Loss: 0.0654 Acc: 0.3300\n",
      "Training complete in 0m 31s\n",
      "Best val Acc: 0.330000\n"
     ]
    }
   ],
   "source": [
    "# Criteria NLLLoss which is recommended with Softmax final layer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optim = torch.optim.Adam(resnet20.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 4 epochs\n",
    "sched = torch.optim.lr_scheduler.StepLR(optimizer=optim, step_size=4, gamma=0.1)\n",
    "\n",
    "# Number of epochs\n",
    "eps=5\n",
    "\n",
    "resnet20_trained = train(resnet20, loss_fn, optim, sched, eps, trainloader_augmented, valloader_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform given images without rotation for fashion classification\n",
    "\n",
    "def my_classification_transforms(image):\n",
    "    image = TF.to_pil_image(image)\n",
    "    image = TF.resize(image, 32, interpolation=2)\n",
    "    image = TF.to_tensor(image)\n",
    "    image = TF.normalize(image, (0.5, ), (0.5, ))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMinstClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, target, transform):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        datapoint = self.transform(self.data[index])\n",
    "        targetpoint = self.target[index]\n",
    "\n",
    "        return datapoint, targetpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader for classification -> only a subset\n",
    "batch_size=32\n",
    "n_train = int(len(trainset) * 0.8)\n",
    "\n",
    "train_augmented_classification = FashionMinstClassificationDataset(\n",
    "#     data=trainset.data[:n_train], \n",
    "    data=trainset.data[:50], \n",
    "#     target=trainset.targets[:n_train], \n",
    "    target=trainset.targets[:50], \n",
    "    transform=my_classification_transforms)\n",
    "trainloader_classification = DataLoader(train_augmented_classification, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "val_augmented_classification = FashionMinstClassificationDataset(\n",
    "#     data=trainset.data[n_train:], \n",
    "    data=trainset.data[100:150],\n",
    "#     target=trainset.targets[n_train:], \n",
    "    target=trainset.targets[100:150], \n",
    "    transform=my_classification_transforms)\n",
    "valloader_classification = DataLoader(val_augmented_classification, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "test_augmented_classification = FashionMinstClassificationDataset(\n",
    "    data=testset.data, \n",
    "    target=testset.targets, \n",
    "    transform=my_classification_transforms)\n",
    "testloader_classification = DataLoader(test_augmented_classification, batch_size=batch_size, shuffle=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "train Loss: 0.1023 Acc: 0.0600\n",
      "val Loss: 0.0979 Acc: 0.0800\n",
      "Epoch 2/5\n",
      "train Loss: 0.0979 Acc: 0.1400\n",
      "val Loss: 0.0973 Acc: 0.1000\n",
      "Epoch 3/5\n",
      "train Loss: 0.0965 Acc: 0.1800\n",
      "val Loss: 0.0966 Acc: 0.1000\n",
      "Epoch 4/5\n",
      "train Loss: 0.0931 Acc: 0.1800\n",
      "val Loss: 0.0969 Acc: 0.1400\n",
      "Epoch 5/5\n",
      "train Loss: 0.0926 Acc: 0.1800\n",
      "val Loss: 0.0976 Acc: 0.1400\n",
      "Training complete in 0m 10s\n",
      "Best val Acc: 0.140000\n"
     ]
    }
   ],
   "source": [
    "# Criteria NLLLoss which is recommended with Softmax final layer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# freeze all layers\n",
    "for param in resnet20_trained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# # unfreeze layer3\n",
    "# for param in resnet20_trained.layer3.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# unfreeze fc layer\n",
    "for param in resnet20_trained.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "resnet20_trained.fc = nn.Linear(64, 10)\n",
    "    \n",
    "# # remove last linear layer\n",
    "# removed = list(resnet20_trained.children())[:-1]\n",
    "# resnet20_trained = torch.nn.Sequential(*self.removed)\n",
    "\n",
    "# # add new last linear layer\n",
    "# resnet20_trained = torch.nn.Sequential(resnet20_trained, torch.nn.Linear(2048,10))\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optim = torch.optim.Adam(resnet20.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 4 epochs\n",
    "sched = torch.optim.lr_scheduler.StepLR(optimizer=optim, step_size=4, gamma=0.1)\n",
    "\n",
    "# Number of epochs\n",
    "eps=5\n",
    "\n",
    "resnet20_trainedClassification = train(resnet20_trained, loss_fn, optim, sched, eps, trainloader_classification, valloader_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FashionMinstAugmentedDataset at 0x7ff3fb93d950>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader_augmented.dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
